akka {
  loglevel = "ERROR"

  http {
    host-connection-pool {
      max-open-requests = 4096
    }
  }

  remote {
    log-remote-lifecycle-events = off
    enabled-transports = ["akka.remote.netty.tcp"]
    netty.tcp {
      hostname = "127.0.0.1"
      port = 0
    }
  }

  actor {
    provider = "akka.remote.RemoteActorRefProvider"
    warn-about-java-serializer-usage = off
  }
}


affinity {

  cluster {
    num.partitions = 2
    coordinator {
      class = "io.amient.affinity.core.cluster.CoordinatorZk"
      zookeeper.timeout.connect.ms = 1000
      zookeeper.timeout.session.ms = 3000
      zookeeper.root = "/affinity"
    }
  }

  node {
    name = "KafkaSystemTests"

    region {
      partitions = [0, 1]
    }

    gateway {
      http {
        host = "127.0.0.1"
      }
    }
  }

  state {
    consistency-test {
      memstore.class = "io.amient.affinity.core.storage.MemStoreSimpleMap"
      storage {
        class = "io.amient.affinity.core.storage.kafka.KafkaStorage"
        kafka {
          topic = "consistency-test"
          producer {
            acks = "all"
            retries = 3
            linger.ms = 10
            compression.type = "gzip"
          }
        }
      }
    }
    throughput-test {
      memstore.class = "io.amient.affinity.core.storage.MemStoreConcurrentMap"
      storage {
        class = "io.amient.affinity.core.storage.kafka.KafkaStorage"
        kafka {
          topic = "throughput-test"
          producer {
            acks = "0"
            retries = 0
            linger.ms = 50
            compression.type = "none"
          }
        }
      }
    }
    failure-test {
      memstore.class = "io.amient.affinity.core.storage.MemStoreConcurrentMap"
      storage {
        class = "io.amient.affinity.testutil.storage.FailingKafkaStorage"
        kafka {
          topic = "failure-test"
          producer {
            acks = "0"
            retries = 0
            linger.ms = 50
            compression.type = "none"
          }
        }
      }
    }
  }

}



